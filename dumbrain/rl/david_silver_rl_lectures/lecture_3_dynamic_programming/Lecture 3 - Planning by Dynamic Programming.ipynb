{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import doctest\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def directionToPosition( start, direction ):\n",
    "    \"\"\"\n",
    "    >>> directionToPosition( [1, 1], 1 )\n",
    "    array([1, 2])\n",
    "    >>> directionToPosition( [0, 0], 0 )\n",
    "    array([0, 0])\n",
    "    >>> directionToPosition( [0, 3], 1 )\n",
    "    array([0, 3])\n",
    "    >>> directionToPosition( [3, 0], 2 )\n",
    "    array([3, 0])\n",
    "    >>> directionToPosition( [0, 0], 3 )\n",
    "    array([0, 0])\n",
    "    \"\"\"\n",
    "    if ( start[ 0 ] == 0 and start[ 1 ] == 0 ) or ( start[ 0 ] == 3 and start[ 1 ] == 3 ):\n",
    "        return np.copy( start )\n",
    "    directions = [\n",
    "        [ -1,  0 ],\n",
    "        [  0, +1 ],\n",
    "        [ +1,  0 ],\n",
    "        [  0, -1 ]\n",
    "    ]\n",
    "    start = np.copy( start )\n",
    "    end = np.copy( start )\n",
    "    end[ 0 ] += directions[ direction ][ 0 ]\n",
    "    end[ 1 ] += directions[ direction ][ 1 ] \n",
    "    if end[ 0 ] < 0 or end[ 0 ] > 3 or end[ 1 ] < 0 or end[ 1 ] > 3:\n",
    "        return start\n",
    "    return end\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratative Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1.  0.]]\n",
      "[[ 0.   -1.75 -2.   -2.  ]\n",
      " [-1.75 -2.   -2.   -2.  ]\n",
      " [-2.   -2.   -2.   -1.75]\n",
      " [-2.   -2.   -1.75  0.  ]]\n",
      "[[ 0.     -2.4375 -2.9375 -3.    ]\n",
      " [-2.4375 -2.875  -3.     -2.9375]\n",
      " [-2.9375 -3.     -2.875  -2.4375]\n",
      " [-3.     -2.9375 -2.4375  0.    ]]\n"
     ]
    }
   ],
   "source": [
    "leave_costs = np.full( ( 4, 4 ), -1 )\n",
    "leave_costs[ 0, 0 ] = 0\n",
    "leave_costs[ 3, 3 ] = 0\n",
    "\n",
    "def randomPolicy( position ):\n",
    "    return np.full( ( 4 ), 0.25 )\n",
    "\n",
    "def evaluatePolicy( policy, k_max=4, print_intermediate=False, v_k=None, in_place=False ):\n",
    "    \"\"\"\n",
    "    Evaluates a policy\n",
    "    :param policy: Function that returns the chance of taking each action\n",
    "    \"\"\"\n",
    "    if v_k is None:\n",
    "        v_k = np.zeros( (4, 4), dtype=np.float )\n",
    "    for k in range( k_max ):\n",
    "        if print_intermediate:\n",
    "            print( v_k )\n",
    "        v_new = v_k\n",
    "        if not in_place:\n",
    "            v_new = v_k.copy()\n",
    "        # Go through all states\n",
    "        for x in range( 4 ):\n",
    "            for y in range( 4 ):\n",
    "                choice = policy( np.array( [ x, y ] ) )\n",
    "                total_reward = 0.0\n",
    "                for direction in range( 4 ):\n",
    "                    new_position = directionToPosition( np.array( [ x, y ] ), direction )\n",
    "                    total_reward += choice[ direction ] * ( leave_costs[ x, y ] + v_k[ new_position[ 0 ], new_position[ 1 ] ] )\n",
    "                v_new[ x, y ] = total_reward\n",
    "        v_k = v_new\n",
    "    return v_k\n",
    "\n",
    "v_k_4 = evaluatePolicy( randomPolicy, 4, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -6.13796997 -8.35235596 -8.96731567]\n",
      " [-6.13796997 -7.73739624 -8.42782593 -8.35235596]\n",
      " [-8.35235596 -8.42782593 -7.73739624 -6.13796997]\n",
      " [-8.96731567 -8.35235596 -6.13796997  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def generateGreedyPolicy( v_k ):\n",
    "    \"\"\"\n",
    "    >>> v_k_test = evaluatePolicy( randomPolicy, 4 )\n",
    "    >>> greedy_policy = generateGreedyPolicy( v_k_test )\n",
    "    >>> greedy_policy( np.array( [ 1, 1 ] ) )\n",
    "    array([0.5, 0. , 0. , 0.5])\n",
    "    \"\"\"\n",
    "    def greedyPolicy( position ):\n",
    "        direction_values = np.zeros( ( 4 ), dtype=np.float )\n",
    "        for direction in range( 4 ):\n",
    "            new_position = directionToPosition( position, direction )\n",
    "            direction_values[ direction ] = v_k[ new_position[ 0 ], new_position[ 1 ] ]\n",
    "        choices = np.zeros( ( 4 ), dtype=np.float )\n",
    "\n",
    "        choices[ direction_values == direction_values.max() ] = 1\n",
    "        total_choices = np.count_nonzero( choices )\n",
    "        choices[ choices == 1 ] /= total_choices\n",
    "\n",
    "        return choices\n",
    "    return greedyPolicy\n",
    "doctest.testmod()\n",
    "\n",
    "k_max = 10\n",
    "V = evaluatePolicy( randomPolicy, k_max=k_max )\n",
    "for i in range( 3 ):\n",
    "    pi = generateGreedyPolicy( V )\n",
    "    V = evaluatePolicy( randomPolicy, k_max=k_max )\n",
    "print( V )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration\n",
    "\n",
    "> (k_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_costs[ 3, 3 ] = -1\n",
    "# Make gridworld the Value Iteration example from the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]]\n",
      "[[ 0. -1. -2. -2.]\n",
      " [-1. -2. -2. -2.]\n",
      " [-2. -2. -2. -2.]\n",
      " [-2. -2. -2. -2.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -3.]\n",
      " [-2. -3. -3. -3.]\n",
      " [-3. -3. -3. -3.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -4.]\n",
      " [-2. -3. -4. -4.]\n",
      " [-3. -4. -4. -4.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -4.]\n",
      " [-2. -3. -4. -5.]\n",
      " [-3. -4. -5. -5.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -4.]\n",
      " [-2. -3. -4. -5.]\n",
      " [-3. -4. -5. -6.]]\n"
     ]
    }
   ],
   "source": [
    "k_max = 1\n",
    "V = evaluatePolicy( randomPolicy, k_max=k_max )\n",
    "for i in range( 5 ):\n",
    "    print( V )\n",
    "    pi = generateGreedyPolicy( V )\n",
    "    V = evaluatePolicy( pi, k_max=k_max, v_k=V )\n",
    "print( V )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions: In-Place Value Iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]]\n",
      "[[ 0. -1. -2. -2.]\n",
      " [-1. -2. -2. -2.]\n",
      " [-2. -2. -2. -2.]\n",
      " [-2. -2. -2. -2.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -3.]\n",
      " [-2. -3. -3. -3.]\n",
      " [-3. -3. -3. -3.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -4.]\n",
      " [-2. -3. -4. -4.]\n",
      " [-3. -4. -4. -4.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -4.]\n",
      " [-2. -3. -4. -5.]\n",
      " [-3. -4. -5. -5.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -4.]\n",
      " [-2. -3. -4. -5.]\n",
      " [-3. -4. -5. -6.]]\n"
     ]
    }
   ],
   "source": [
    "k_max = 1\n",
    "V = evaluatePolicy( randomPolicy, k_max=k_max )\n",
    "for i in range( 5 ):\n",
    "    print( V )\n",
    "    pi = generateGreedyPolicy( V )\n",
    "    V = evaluatePolicy( pi, k_max=k_max, v_k=V, in_place=True )\n",
    "print( V )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
