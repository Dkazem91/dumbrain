{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR\n",
    "\n",
    "Train a toy model to predict the XOR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array( [\n",
    "    [ 0, 0, 0 ],\n",
    "    [ 1, 1, 0 ],\n",
    "    [ 0, 1, 1 ],\n",
    "    [ 1, 0, 1 ]\n",
    "], dtype=float )\n",
    "\n",
    "Y = samples[ :, 0:1  ]\n",
    "X = samples[ :, 1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 : (0.2519291, array([[0.54613286],\n",
      "       [0.5565019 ],\n",
      "       [0.5288474 ],\n",
      "       [0.51721096]], dtype=float32))\n",
      "---- 5000 : (0.24990584, array([[0.5086956 ],\n",
      "       [0.51529825],\n",
      "       [0.48901144],\n",
      "       [0.4834884 ]], dtype=float32))\n",
      "---- 10000 : (0.24940872, array([[0.5088879 ],\n",
      "       [0.51300377],\n",
      "       [0.4877377 ],\n",
      "       [0.4865659 ]], dtype=float32))\n",
      "---- 15000 : (0.24881418, array([[0.50845367],\n",
      "       [0.51261866],\n",
      "       [0.4865991 ],\n",
      "       [0.487738  ]], dtype=float32))\n",
      "---- 20000 : (0.2479246, array([[0.50726384],\n",
      "       [0.5139596 ],\n",
      "       [0.4852606 ],\n",
      "       [0.48748785]], dtype=float32))\n",
      "---- 25000 : (0.24639621, array([[0.50492334],\n",
      "       [0.517353  ],\n",
      "       [0.4832177 ],\n",
      "       [0.48600602]], dtype=float32))\n",
      "---- 30000 : (0.243527, array([[0.5005455 ],\n",
      "       [0.52388287],\n",
      "       [0.47958273],\n",
      "       [0.48340052]], dtype=float32))\n",
      "---- 35000 : (0.23784964, array([[0.49229607],\n",
      "       [0.535898  ],\n",
      "       [0.47271407],\n",
      "       [0.48019823]], dtype=float32))\n",
      "---- 40000 : (0.22652856, array([[0.47687978],\n",
      "       [0.5571379 ],\n",
      "       [0.45965958],\n",
      "       [0.4791486 ]], dtype=float32))\n",
      "---- 45000 : (0.20517519, array([[0.44987652],\n",
      "       [0.5898529 ],\n",
      "       [0.43593806],\n",
      "       [0.4900497 ]], dtype=float32))\n",
      "---- 50000 : (0.16939554, array([[0.40652847],\n",
      "       [0.6301265 ],\n",
      "       [0.3959927 ],\n",
      "       [0.5323461 ]], dtype=float32))\n",
      "---- 55000 : (0.12118291, array([[0.34223053],\n",
      "       [0.67557186],\n",
      "       [0.33648407],\n",
      "       [0.6138203 ]], dtype=float32))\n",
      "---- 60000 : (0.076872386, array([[0.26872984],\n",
      "       [0.7270187 ],\n",
      "       [0.27084583],\n",
      "       [0.7043692 ]], dtype=float32))\n",
      "---- 65000 : (0.04834515, array([[0.2088256 ],\n",
      "       [0.7742635 ],\n",
      "       [0.21793297],\n",
      "       [0.77345926]], dtype=float32))\n",
      "---- 70000 : (0.032297276, array([[0.16739514],\n",
      "       [0.8105073 ],\n",
      "       [0.18064018],\n",
      "       [0.8193633 ]], dtype=float32))\n",
      "---- 75000 : (0.023104414, array([[0.13926728],\n",
      "       [0.836929  ],\n",
      "       [0.15459302],\n",
      "       [0.84989625]], dtype=float32))\n",
      "---- 80000 : (0.017492265, array([[0.11953366],\n",
      "       [0.8564037 ],\n",
      "       [0.13580616],\n",
      "       [0.8710909 ]], dtype=float32))\n",
      "---- 85000 : (0.013836019, array([[0.10510337],\n",
      "       [0.8711662 ],\n",
      "       [0.12172786],\n",
      "       [0.8865031 ]], dtype=float32))\n",
      "---- 90000 : (0.0113176415, array([[0.09414294],\n",
      "       [0.88269675],\n",
      "       [0.11080949],\n",
      "       [0.8981723 ]], dtype=float32))\n",
      "---- 95000 : (0.00950264, array([[0.08554984],\n",
      "       [0.89193624],\n",
      "       [0.10209008],\n",
      "       [0.907309  ]], dtype=float32))\n",
      "---- 100000 : (0.008145162, array([[0.07862982],\n",
      "       [0.8995118 ],\n",
      "       [0.09496056],\n",
      "       [0.91466177]], dtype=float32))\n",
      "---- 105000 : (0.007098615, array([[0.07293449],\n",
      "       [0.90584683],\n",
      "       [0.08901145],\n",
      "       [0.92070836]], dtype=float32))\n",
      "---- 110000 : (0.0062710093, array([[0.06815983],\n",
      "       [0.911224  ],\n",
      "       [0.08395813],\n",
      "       [0.9257832 ]], dtype=float32))\n",
      "---- 115000 : (0.005603241, array([[0.06409416],\n",
      "       [0.915858  ],\n",
      "       [0.0796151 ],\n",
      "       [0.9300968 ]], dtype=float32))\n",
      "---- 120000 : (0.005054213, array([[0.06059027],\n",
      "       [0.9198964 ],\n",
      "       [0.07583255],\n",
      "       [0.93382967]], dtype=float32))\n",
      "---- 125000 : (0.004596494, array([[0.0575323 ],\n",
      "       [0.92345613],\n",
      "       [0.07250983],\n",
      "       [0.93707645]], dtype=float32))\n",
      "---- 130000 : (0.0042092074, array([[0.05483515],\n",
      "       [0.92660993],\n",
      "       [0.06954469],\n",
      "       [0.9399386 ]], dtype=float32))\n",
      "---- 135000 : (0.0038779355, array([[0.05243768],\n",
      "       [0.9294304 ],\n",
      "       [0.06689578],\n",
      "       [0.94249415]], dtype=float32))\n",
      "---- 140000 : (0.0035923396, array([[0.05030006],\n",
      "       [0.9319784 ],\n",
      "       [0.06450868],\n",
      "       [0.94476455]], dtype=float32))\n",
      "---- 145000 : (0.0033432685, array([[0.04836877],\n",
      "       [0.9342743 ],\n",
      "       [0.06234295],\n",
      "       [0.9468302 ]], dtype=float32))\n",
      "---- 150000 : (0.0031244908, array([[0.04662962],\n",
      "       [0.93640184],\n",
      "       [0.06039065],\n",
      "       [0.9486981 ]], dtype=float32))\n",
      "---- 155000 : (0.0029309297, array([[0.04503066],\n",
      "       [0.9383136 ],\n",
      "       [0.05856914],\n",
      "       [0.95039755]], dtype=float32))\n",
      "---- 160000 : (0.002758301, array([[0.04356005],\n",
      "       [0.9400892 ],\n",
      "       [0.05690138],\n",
      "       [0.9519515 ]], dtype=float32))\n",
      "---- 165000 : (0.0026043965, array([[0.04222004],\n",
      "       [0.9417176 ],\n",
      "       [0.05536243],\n",
      "       [0.9533822 ]], dtype=float32))\n",
      "---- 170000 : (0.0024652542, array([[0.04098467],\n",
      "       [0.94324577],\n",
      "       [0.05393459],\n",
      "       [0.9547088 ]], dtype=float32))\n",
      "---- 175000 : (0.00233948, array([[0.03983163],\n",
      "       [0.9446621 ],\n",
      "       [0.05261204],\n",
      "       [0.95594263]], dtype=float32))\n",
      "---- 180000 : (0.002225938, array([[0.03876104],\n",
      "       [0.94595927],\n",
      "       [0.05136235],\n",
      "       [0.95707166]], dtype=float32))\n",
      "---- 185000 : (0.002121484, array([[0.03778394],\n",
      "       [0.947214  ],\n",
      "       [0.05022864],\n",
      "       [0.9581786 ]], dtype=float32))\n",
      "---- 190000 : (0.0020267535, array([[0.03684485],\n",
      "       [0.94837934],\n",
      "       [0.04914291],\n",
      "       [0.9591374 ]], dtype=float32))\n",
      "---- 195000 : (0.0019388815, array([[0.03598179],\n",
      "       [0.94946986],\n",
      "       [0.04811152],\n",
      "       [0.9600898 ]], dtype=float32))\n",
      "[[0.03515927]\n",
      " [0.950477  ]\n",
      " [0.04712609]\n",
      " [0.96094954]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder( tf.float32, shape=( 4, 2 ) )\n",
    "y = tf.placeholder( tf.float32, shape=( 4, 1 ) )\n",
    "\n",
    "l1_weights = tf.Variable( tf.random_uniform( ( 2, 5 ), -1, 1 ) )\n",
    "l1_biases = tf.Variable( tf.zeros( ( 5 ) ) )\n",
    "\n",
    "l1 = tf.sigmoid( tf.matmul( x, l1_weights ) + l1_biases )\n",
    "\n",
    "l2_weights = tf.Variable( tf.random_uniform( ( 5, 1 ), -1, 1 ) )\n",
    "l2_biases = tf.Variable( tf.zeros( ( 1 ) ) )\n",
    "\n",
    "output = tf.sigmoid( tf.matmul( l1, l2_weights ) + l2_biases )\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y - output))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer( 0.01 ).minimize( loss )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run( init )\n",
    "\n",
    "for train_sessions in range( 200000 ):\n",
    "    feed_dict = { x: X, y: Y }\n",
    "    _ = sess.run( train_step, feed_dict=feed_dict )\n",
    "    if ( train_sessions ) % 5000 == 0:\n",
    "        print( '----', train_sessions, ':', sess.run( ( loss, output ), feed_dict=feed_dict ) )\n",
    "\n",
    "final_outputs = sess.run( output, feed_dict={ x: X, y: Y } )\n",
    "print( final_outputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
