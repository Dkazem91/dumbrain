{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from dumbrain.ml.kaggle.lib import initCompetition, submit\n",
    "from dumbrain.lib.cleaners import *\n",
    "from dumbrain.lib.cleaners.column import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPETITION_NAME = 'titanic'\n",
    "RANDOM_STATE = 4111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file, train_file, example_output = initCompetition( COMPETITION_NAME )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.read_csv( train_file )\n",
    "all_test_data = pd.read_csv( test_file )\n",
    "all_example_data = pd.read_csv( example_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_uncleaned = all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Mr 0.16808358149081604\n",
      "57\n",
      "Score Mrs 0.007817496278279823\n",
      "11\n",
      "Score Miss 0.39980187807731593\n",
      "14\n",
      "Score Master -0.3181188549468281\n",
      "4\n",
      "Score Misc -0.23013750799417143\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def predictAgePerTitle( _data, _test_data ):\n",
    "    lr_cleaners = [\n",
    "        RemoveColumnCleaner( [ 'PassengerId', 'Survived', 'Name', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Sex' ] )\n",
    "    #     DummyColumnCleaner( 'Title', ['Mr', 'Mrs', 'Miss', 'Master', 'Royal', 'Officer', 'Major', 'Col','Capt'] ),\n",
    "    ]\n",
    "    \n",
    "    def getTitle( name ):\n",
    "        for token in name.split( ' ' ):\n",
    "            if '.' in token:\n",
    "                return token.replace( '.', '' )\n",
    "        return None\n",
    "\n",
    "    _data[ 'Title' ] = _data[ 'Name' ].apply( getTitle )\n",
    "    _test_data[ 'Title' ] = _test_data[ 'Name' ].apply( getTitle )\n",
    "\n",
    "    groups = {\n",
    "        'Misc': [ 'Col', 'Major', 'Capt', 'Jonkheer', 'Don', 'Sir', 'Lady', 'Countess', 'Dr', 'Rev' ],\n",
    "        'Mrs': [ 'Ms', 'Mme', 'Mlle' ]\n",
    "    }\n",
    "    for to_title, from_titles in groups.items():\n",
    "        for from_title in from_titles:\n",
    "            _data.loc[ _data[ 'Title' ] == from_title, 'Title' ] = to_title\n",
    "            _test_data.loc[ _test_data[ 'Title' ] == from_title, 'Title' ] = to_title\n",
    "\n",
    "    for title in _data.Title.unique():\n",
    "        lr_cleaned = cleanData( lr_cleaners, _data[ _data.Title == title ] )\n",
    "        lr_cleaned = lr_cleaned.drop( 'Title', axis=1 )\n",
    "\n",
    "        test = lr_cleaned[ lr_cleaned.Age.isna() ]\n",
    "        lr_cleaned_train = lr_cleaned.drop( test.index )\n",
    "\n",
    "        age_model = LinearRegression()\n",
    "        age_model.fit( lr_cleaned_train.drop( [ 'Age' ], axis=1 ), lr_cleaned_train[ 'Age' ] )\n",
    "\n",
    "        if test.shape[ 0 ] != 0:\n",
    "            print( 'Score', title, cross_val_score( age_model, lr_cleaned_train.drop( [ 'Age' ], axis=1 ), lr_cleaned_train[ 'Age' ], cv=2 ).mean() )\n",
    "            _data.loc[ ( _data.Title == title ) & ( _data.Age.isna() ), 'Age' ] = age_model.predict( test.drop( 'Age', axis=1 ) )\n",
    "\n",
    "        _test_filter = ( _test_data.Title == title ) & ( _test_data.Age.isna() )\n",
    "        _test_cleaned = cleanData( lr_cleaners, _test_data.loc[ _test_filter ] ).drop( 'Title', axis=1 )\n",
    "        print( len( _test_cleaned ) )\n",
    "        if len( _test_cleaned ) != 0:\n",
    "            _test_data.loc[ _test_filter, 'Age' ] = age_model.predict( _test_cleaned.drop( 'Age', axis=1 ) )\n",
    "\n",
    "predictAgePerTitle( all_train_data, all_test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>_Braund_Name</th>\n",
       "      <th>_Cumings_Name</th>\n",
       "      <th>_Heikkinen_Name</th>\n",
       "      <th>_Futrelle_Name</th>\n",
       "      <th>_Allen_Name</th>\n",
       "      <th>...</th>\n",
       "      <th>_female_Sex</th>\n",
       "      <th>_Mr_Title</th>\n",
       "      <th>_Mrs_Title</th>\n",
       "      <th>_Miss_Title</th>\n",
       "      <th>_Master_Title</th>\n",
       "      <th>_Misc_Title</th>\n",
       "      <th>_S_Embarked</th>\n",
       "      <th>_C_Embarked</th>\n",
       "      <th>_Q_Embarked</th>\n",
       "      <th>isAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age     Fare  Cabin  _Braund_Name  _Cumings_Name  \\\n",
       "0       0.0     3.0  22.0   7.2500    0.0           1.0            0.0   \n",
       "1       1.0     1.0  38.0  71.2833    3.0           0.0            1.0   \n",
       "2       1.0     3.0  26.0   7.9250    0.0           0.0            0.0   \n",
       "3       1.0     1.0  35.0  53.1000    4.0           0.0            0.0   \n",
       "4       0.0     3.0  35.0   8.0500    0.0           0.0            0.0   \n",
       "\n",
       "   _Heikkinen_Name  _Futrelle_Name  _Allen_Name  ...  _female_Sex  _Mr_Title  \\\n",
       "0              0.0             0.0          0.0  ...          0.0        1.0   \n",
       "1              0.0             0.0          0.0  ...          1.0        0.0   \n",
       "2              1.0             0.0          0.0  ...          1.0        0.0   \n",
       "3              0.0             1.0          0.0  ...          1.0        0.0   \n",
       "4              0.0             0.0          1.0  ...          0.0        1.0   \n",
       "\n",
       "   _Mrs_Title  _Miss_Title  _Master_Title  _Misc_Title  _S_Embarked  \\\n",
       "0         0.0          0.0            0.0          0.0          1.0   \n",
       "1         1.0          0.0            0.0          0.0          0.0   \n",
       "2         0.0          1.0            0.0          0.0          1.0   \n",
       "3         1.0          0.0            0.0          0.0          1.0   \n",
       "4         0.0          0.0            0.0          0.0          1.0   \n",
       "\n",
       "   _C_Embarked  _Q_Embarked  isAlone  \n",
       "0          0.0          0.0      1.0  \n",
       "1          1.0          0.0      1.0  \n",
       "2          0.0          0.0      0.0  \n",
       "3          0.0          0.0      1.0  \n",
       "4          0.0          0.0      0.0  \n",
       "\n",
       "[5 rows x 683 columns]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getFamilySize( data ):\n",
    "    return data.SibSp + data.Parch\n",
    "\n",
    "def isAlone( data ):\n",
    "    return np.where( data.FamilySize == 1, 1, 0 )\n",
    "\n",
    "def convertToInt16( data ):\n",
    "    return np.int16( data )\n",
    "\n",
    "def getLastName( data ):\n",
    "    return data.split( ',' )[ 0 ].strip()\n",
    "\n",
    "def strlen( data ):\n",
    "    if isinstance( data, float ) and  np.isnan( data ):\n",
    "        return 0\n",
    "    return len( data )\n",
    "\n",
    "def nameScoreMean( data ):\n",
    "    return data[ 'Name_score' ].where( ~data[ 'Name_score' ].isna(), data[ 'Name_score' ].mean() )\n",
    "\n",
    "def fareMean( data ):\n",
    "    return data[ 'Fare' ].where( ~data[ 'Fare' ].isna(), data[ 'Fare' ].mean() )\n",
    "\n",
    "last_names = train_data_uncleaned.Name.apply( getLastName )\n",
    "last_names_dataset = pd.DataFrame( { 'Name': last_names, 'Survived': train_data_uncleaned.Survived } )\n",
    "name_sentiment_cleaner = BasicTokenSentimentColumnCleaner( 'Name', last_names_dataset, 'Survived' )\n",
    "\n",
    "# titles = train_data_uncleaned.Title\n",
    "# last_names_dataset = pd.DataFrame( { 'Title': last_names, 'Survived': train_data_uncleaned.Survived } )\n",
    "# name_sentiment_cleaner = BasicTokenSentimentColumnCleaner( 'Name', last_names_dataset, 'Survived' )\n",
    "\n",
    "cleaners = [\n",
    "    RemoveColumnCleaner( 'PassengerId' ),\n",
    "    CalculatedColumnCleaner( 'Fare', fareMean ),\n",
    "    MapColumnCleaner( 'Name', getLastName ),\n",
    "    DummyColumnCleaner( 'Name', last_names ),\n",
    "    DummyColumnCleaner( 'Sex', [ 'male', 'female' ] ),\n",
    "    RemoveColumnCleaner( 'Sex' ),\n",
    "#     RemoveColumnCleaner( 'Fare' ),\n",
    "#     RemoveColumnCleaner( 'Title' ),\n",
    "    DummyColumnCleaner( 'Title', train_data_uncleaned.Title.unique() ),\n",
    "#     DummyColumnCleaner( 'Pclass', [ 1, 2, 3 ] ),\n",
    "    RemoveColumnCleaner( 'Ticket' ),                     # Todo: Use this data\n",
    "#     MapColumnCleaner( 'Ticket', strlen ),\n",
    "#     RemoveColumnCleaner( 'Cabin' ),                      # Todo: Use this data\n",
    "    MapColumnCleaner( 'Cabin', strlen ),\n",
    "    DummyColumnCleaner( 'Embarked', [ 'S', 'C', 'Q' ] ),\n",
    "    CalculatedColumnCleaner( 'FamilySize', getFamilySize ),\n",
    "    RemoveColumnCleaner( 'SibSp' ),\n",
    "    RemoveColumnCleaner( 'Parch' ),\n",
    "    CalculatedColumnCleaner( 'isAlone', isAlone ),\n",
    "    RemoveColumnCleaner( 'FamilySize' ),\n",
    "    ConvertDataCleaner( np.float64 ),\n",
    "    \n",
    "]\n",
    "\n",
    "train_data = cleanData( cleaners, train_data_uncleaned )\n",
    "# validate_data = cleanData( cleaners, validate_data_uncleaned )\n",
    "\n",
    "# print( pd.get_dummies( train_data.Name ).shape )\n",
    "\n",
    "train_data.head()\n",
    "\n",
    "# name_sentiment_cleaner.sentiments.sort_values( 'scores', ascending=False ).head()\n",
    "# train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = train_data.drop( 'Survived', axis=1 )\n",
    "y_train_data = train_data[ 'Survived' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreModel( model, x_train_data, y_train_data ):\n",
    "    return cv_score\n",
    "\n",
    "def predict( model, _all_test_data ):\n",
    "    test_data_cleaned = cleanData( cleaners, _all_test_data )\n",
    "    predicted = model.predict( test_data_cleaned )\n",
    "    output = pd.DataFrame( { 'PassengerId': all_test_data[ 'PassengerId' ], 'Survived': predicted.astype( np.int64 ) } )\n",
    "    output = output.set_index( 'PassengerId' )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold( 5, random_state=RANDOM_STATE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77094972, 0.82122905, 0.8258427 , 0.74157303, 0.83615819])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier( n_estimators = 10, max_depth = 10, random_state=RANDOM_STATE )\n",
    "cross_val_score( model, x_train_data, y_train_data, cv=kfold )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.84357542, 0.82122905, 0.80898876, 0.76404494, 0.83615819])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Grid Parameter Search\n",
    "cv_score = cross_val_score( model, x_train_data, y_train_data, cv=kfold )\n",
    "\n",
    "RF = RandomForestClassifier( random_state=RANDOM_STATE )\n",
    "PRF = [ { 'n_estimators': [ 10, 100 ], 'max_depth': [ 3, 6, 10 ] , 'criterion': [ 'gini', 'entropy' ] } ]\n",
    "GSRF = GridSearchCV( estimator=RF, param_grid=PRF, scoring='accuracy', cv=kfold )\n",
    "cross_val_score( GSRF, x_train_data, y_train_data, cv=kfold )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=4111, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=4111, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': [10, 100], 'max_depth': [3, 6, 10], 'criterion': ['gini', 'entropy']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSRF.fit( x_train_data, y_train_data )\n",
    "# predict( GSRF, all_test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.84357542, 0.82122905, 0.80898876, 0.76404494, 0.83615819])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score( GSRF, x_train_data, y_train_data, cv=kfold )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict( GSRF, all_test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=20)]: Done 280 out of 280 | elapsed:   47.5s finished\n",
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=20)]: Done 280 out of 280 | elapsed:   42.5s finished\n",
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=20)]: Done 280 out of 280 | elapsed:   42.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=20)]: Done 280 out of 280 | elapsed:   42.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=20)]: Done 280 out of 280 | elapsed:   43.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.86592179, 0.84916201, 0.84269663, 0.80337079, 0.86440678])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = make_pipeline( StandardScaler(), SVC( random_state=RANDOM_STATE ) )\n",
    "# r = [ 0.0001, 0.001, 0.1, 1, 10, 50, 100 ]\n",
    "# svc_model.fit( x_train_data, y_train_data )\n",
    "\n",
    "r = [ 0.0001, 0.001, 0.1, 1, 10, 50, 100 ]\n",
    "parameters_svc = [\n",
    "    { 'svc__C': r, 'svc__kernel': [ 'linear' ] }, \n",
    "    { 'svc__C': r, 'svc__gamma': r, 'svc__kernel': [ 'rbf' ] } \n",
    "]\n",
    "gs_svc_model = GridSearchCV( estimator=svc_model, param_grid=parameters_svc, scoring='accuracy', cv=kfold, verbose=1, n_jobs=20 )\n",
    "\n",
    "gs_svc_cv_score = cross_val_score( gs_svc_model, x_train_data.astype( np.float64 ), y_train_data, cv = kfold )\n",
    "gs_svc_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8451115988548071"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc_cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=20)]: Done 280 out of 280 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=4111, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=4111,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=20,\n",
       "       param_grid=[{'svc__C': [0.0001, 0.001, 0.1, 1, 10, 50, 100], 'svc__kernel': ['linear']}, {'svc__C': [0.0001, 0.001, 0.1, 1, 10, 50, 100], 'svc__gamma': [0.0001, 0.001, 0.1, 1, 10, 50, 100], 'svc__kernel': ['rbf']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc_model.fit( x_train_data.astype( np.float64 ), y_train_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    6.2s finished\n",
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    4.1s finished\n",
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    4.1s finished\n",
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    4.3s finished\n",
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8603352 , 0.83240223, 0.83707865, 0.80337079, 0.85310734])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "r = [ 0.0001, 0.001, 0.1, 1, 10, 50, 100 ]\n",
    "parameters_gb = { 'learning_rate': r }\n",
    "gs_gb_model = GridSearchCV( estimator=gb_model, param_grid=parameters_gb, scoring='accuracy', cv=kfold, verbose=1, n_jobs=-1 )\n",
    "cross_val_score( gs_gb_model, x_train_data, y_train_data, cv=kfold )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    6.4s finished\n",
      "/Users/mike/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=4111, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.0001, 0.001, 0.1, 1, 10, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gb_model.fit( x_train_data, y_train_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>rf</th>\n",
       "      <th>svc</th>\n",
       "      <th>gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015743</td>\n",
       "      <td>0.023574</td>\n",
       "      <td>0.013170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>-0.015743</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813572</td>\n",
       "      <td>0.877715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.023574</td>\n",
       "      <td>0.813572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.013170</td>\n",
       "      <td>0.877715</td>\n",
       "      <td>0.898436</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId        rf       svc        gb\n",
       "PassengerId     1.000000 -0.015743  0.023574  0.013170\n",
       "rf             -0.015743  1.000000  0.813572  0.877715\n",
       "svc             0.023574  0.813572  1.000000  0.898436\n",
       "gb              0.013170  0.877715  0.898436  1.000000"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_cleaned = cleanData( cleaners, all_test_data )\n",
    "\n",
    "predictions = pd.DataFrame( { 'PassengerId': all_test_data.PassengerId } )\n",
    "\n",
    "predictions[ 'rf' ] = GSRF.predict( test_data_cleaned )\n",
    "predictions[ 'svc' ] = gs_svc_model.predict( test_data_cleaned )\n",
    "predictions[ 'gb' ] = gs_gb_model.predict( test_data_cleaned )\n",
    "\n",
    "predictions.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 1\n",
       "894                 0\n",
       "895                 0\n",
       "896                 1"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[ 'output' ] = 0\n",
    "predictions[ 'output' ] = np.where( predictions[[ 'rf', 'svc', 'gb' ]].sum( axis=1 ) >= 2, 1, 0 )\n",
    "predictions\n",
    "\n",
    "output = pd.DataFrame( { 'PassengerId': predictions.PassengerId, 'Survived': predictions.output.astype( np.int64 ) } )\n",
    "output = output.set_index( 'PassengerId' )\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    159\n",
       "dtype: int64"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    149\n",
       "dtype: int64"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_output = predict( gs_svc_model, all_test_data )\n",
    "svc_output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( output != svc_output ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = 'output/results.csv'\n",
    "output.to_csv( output_csv )\n",
    "submit( COMPETITION_NAME, output_csv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
