{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR\n",
    "\n",
    "Train a toy model to predict the XOR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array( [\n",
    "    [ 0, 0, 0 ],\n",
    "    [ 1, 1, 0 ],\n",
    "    [ 0, 1, 1 ],\n",
    "    [ 1, 0, 1 ]\n",
    "], dtype=float )\n",
    "\n",
    "Y = samples[ :, 0:1  ]\n",
    "X = samples[ :, 1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 : (0.2559983, array([[0.41747826],\n",
      "       [0.5043574 ],\n",
      "       [0.46414968],\n",
      "       [0.3766152 ]], dtype=float32))\n",
      "---- 5000 : (0.25080168, array([[0.47826558],\n",
      "       [0.5454691 ],\n",
      "       [0.51629025],\n",
      "       [0.4510784 ]], dtype=float32))\n",
      "---- 10000 : (0.2496028, array([[0.48247537],\n",
      "       [0.5387455 ],\n",
      "       [0.51342636],\n",
      "       [0.46216515]], dtype=float32))\n",
      "---- 15000 : (0.24863485, array([[0.48409784],\n",
      "       [0.53644896],\n",
      "       [0.5118417 ],\n",
      "       [0.46771517]], dtype=float32))\n",
      "---- 20000 : (0.24743629, array([[0.48380756],\n",
      "       [0.53776747],\n",
      "       [0.51098865],\n",
      "       [0.46999335]], dtype=float32))\n",
      "---- 25000 : (0.2455135, array([[0.481354  ],\n",
      "       [0.5430231 ],\n",
      "       [0.51050305],\n",
      "       [0.4699895 ]], dtype=float32))\n",
      "---- 30000 : (0.24204367, array([[0.47560295],\n",
      "       [0.5535559 ],\n",
      "       [0.5098018 ],\n",
      "       [0.46824223]], dtype=float32))\n",
      "---- 35000 : (0.23556954, array([[0.46424747],\n",
      "       [0.5716674 ],\n",
      "       [0.5075333 ],\n",
      "       [0.46549687]], dtype=float32))\n",
      "---- 40000 : (0.22385001, array([[0.4435939 ],\n",
      "       [0.5998081 ],\n",
      "       [0.5011749 ],\n",
      "       [0.46400124]], dtype=float32))\n",
      "---- 45000 : (0.20425674, array([[0.4096245 ],\n",
      "       [0.637802  ],\n",
      "       [0.48753136],\n",
      "       [0.47050914]], dtype=float32))\n",
      "---- 50000 : (0.17456743, array([[0.36113334],\n",
      "       [0.6795939 ],\n",
      "       [0.46267766],\n",
      "       [0.4988795 ]], dtype=float32))\n",
      "---- 55000 : (0.13452782, array([[0.3015044 ],\n",
      "       [0.71826345],\n",
      "       [0.41864896],\n",
      "       [0.5611789 ]], dtype=float32))\n",
      "---- 60000 : (0.09185827, array([[0.23918395],\n",
      "       [0.755866  ],\n",
      "       [0.35383016],\n",
      "       [0.6458434 ]], dtype=float32))\n",
      "---- 65000 : (0.059294485, array([[0.18625075],\n",
      "       [0.7931536 ],\n",
      "       [0.28808394],\n",
      "       [0.72303283]], dtype=float32))\n",
      "---- 70000 : (0.039350666, array([[0.1479401 ],\n",
      "       [0.82481307],\n",
      "       [0.23673424],\n",
      "       [0.77913165]], dtype=float32))\n",
      "---- 75000 : (0.027704196, array([[0.1216053 ],\n",
      "       [0.8491118 ],\n",
      "       [0.19989301],\n",
      "       [0.8175049 ]], dtype=float32))\n",
      "---- 80000 : (0.020644018, array([[0.10323677],\n",
      "       [0.86738384],\n",
      "       [0.17338444],\n",
      "       [0.8442148 ]], dtype=float32))\n",
      "---- 85000 : (0.016109498, array([[0.08995583],\n",
      "       [0.8813148 ],\n",
      "       [0.15374155],\n",
      "       [0.8635328 ]], dtype=float32))\n",
      "---- 90000 : (0.013032831, array([[0.07999287],\n",
      "       [0.892192  ],\n",
      "       [0.13869925],\n",
      "       [0.87804747]], dtype=float32))\n",
      "---- 95000 : (0.010845156, array([[0.07227445],\n",
      "       [0.9009048 ],\n",
      "       [0.12684937],\n",
      "       [0.8893365 ]], dtype=float32))\n",
      "---- 100000 : (0.009227909, array([[0.06611721],\n",
      "       [0.9080242 ],\n",
      "       [0.11725594],\n",
      "       [0.8983553 ]], dtype=float32))\n",
      "---- 105000 : (0.007993663, array([[0.06109296],\n",
      "       [0.9139528 ],\n",
      "       [0.10933356],\n",
      "       [0.9057431 ]], dtype=float32))\n",
      "---- 110000 : (0.007026313, array([[0.05691126],\n",
      "       [0.9189737 ],\n",
      "       [0.1026585 ],\n",
      "       [0.91189593]], dtype=float32))\n",
      "---- 115000 : (0.00625113, array([[0.05338014],\n",
      "       [0.92329067],\n",
      "       [0.096967  ],\n",
      "       [0.91712564]], dtype=float32))\n",
      "---- 120000 : (0.0056182947, array([[0.05034755],\n",
      "       [0.92703855],\n",
      "       [0.09203613],\n",
      "       [0.9216145 ]], dtype=float32))\n",
      "---- 125000 : (0.005093499, array([[0.04771484],\n",
      "       [0.9303302 ],\n",
      "       [0.08773286],\n",
      "       [0.92552614]], dtype=float32))\n",
      "---- 130000 : (0.004651433, array([[0.04540676],\n",
      "       [0.9332454 ],\n",
      "       [0.08390665],\n",
      "       [0.92895454]], dtype=float32))\n",
      "---- 135000 : (0.0042757224, array([[0.04335942],\n",
      "       [0.9358465 ],\n",
      "       [0.08051969],\n",
      "       [0.93200177]], dtype=float32))\n",
      "---- 140000 : (0.00395199, array([[0.04153241],\n",
      "       [0.93819815],\n",
      "       [0.07748006],\n",
      "       [0.9347283 ]], dtype=float32))\n",
      "---- 145000 : (0.0036709965, array([[0.0399067 ],\n",
      "       [0.9403362 ],\n",
      "       [0.07473766],\n",
      "       [0.93718314]], dtype=float32))\n",
      "---- 150000 : (0.0034244014, array([[0.03842602],\n",
      "       [0.9422747 ],\n",
      "       [0.07223568],\n",
      "       [0.93941253]], dtype=float32))\n",
      "---- 155000 : (0.0032079332, array([[0.03708561],\n",
      "       [0.9440471 ],\n",
      "       [0.06996182],\n",
      "       [0.9414252 ]], dtype=float32))\n",
      "---- 160000 : (0.0030152635, array([[0.03584779],\n",
      "       [0.945653  ],\n",
      "       [0.06785117],\n",
      "       [0.94326717]], dtype=float32))\n",
      "---- 165000 : (0.0028429125, array([[0.03472552],\n",
      "       [0.9471733 ],\n",
      "       [0.06594624],\n",
      "       [0.9449889 ]], dtype=float32))\n",
      "---- 170000 : (0.0026880712, array([[0.03367621],\n",
      "       [0.9485603 ],\n",
      "       [0.06414205],\n",
      "       [0.9465402 ]], dtype=float32))\n",
      "---- 175000 : (0.0025488348, array([[0.03273151],\n",
      "       [0.94985735],\n",
      "       [0.06249623],\n",
      "       [0.9480007 ]], dtype=float32))\n",
      "---- 180000 : (0.0024214236, array([[0.0318343 ],\n",
      "       [0.9510717 ],\n",
      "       [0.06094283],\n",
      "       [0.94936144]], dtype=float32))\n",
      "---- 185000 : (0.0023066252, array([[0.03101223],\n",
      "       [0.95221937],\n",
      "       [0.05951572],\n",
      "       [0.95060736]], dtype=float32))\n",
      "---- 190000 : (0.002201142, array([[0.03024133],\n",
      "       [0.9532495 ],\n",
      "       [0.05813789],\n",
      "       [0.9517879 ]], dtype=float32))\n",
      "---- 195000 : (0.0021049082, array([[0.02951097],\n",
      "       [0.9542507 ],\n",
      "       [0.05690698],\n",
      "       [0.95291144]], dtype=float32))\n",
      "[[0.02883214]\n",
      " [0.9551894 ]\n",
      " [0.0556877 ]\n",
      " [0.95391995]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder( tf.float32, shape=( 4, 2 ) )\n",
    "y = tf.placeholder( tf.float32, shape=( 4, 1 ) )\n",
    "\n",
    "l1_weights = tf.Variable( tf.random_uniform( ( 2, 5 ), -1, 1 ) )\n",
    "l1_biases = tf.Variable( tf.zeros( ( 5 ) ) )\n",
    "\n",
    "l1 = tf.sigmoid( tf.matmul( x, l1_weights ) + l1_biases )\n",
    "\n",
    "l2_weights = tf.Variable( tf.random_uniform( ( 5, 1 ), -1, 1 ) )\n",
    "l2_biases = tf.Variable( tf.zeros( ( 1 ) ) )\n",
    "\n",
    "output = tf.sigmoid( tf.matmul( l1, l2_weights ) + l2_biases )\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y - output))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer( 0.01 ).minimize( loss )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run( init )\n",
    "\n",
    "for train_sessions in range( 200000 ):\n",
    "    feed_dict = { x: X, y: Y }\n",
    "    _ = sess.run( train_step, feed_dict=feed_dict )\n",
    "    if ( train_sessions ) % 5000 == 0:\n",
    "        print( '----', train_sessions, ':', sess.run( ( loss, output ), feed_dict=feed_dict ) )\n",
    "\n",
    "final_outputs = sess.run( output, feed_dict={ x: X, y: Y } )\n",
    "print( final_outputs )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
