{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR\n",
    "\n",
    "Train a toy model to predic the xor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array( [\n",
    "    [ 0, 0, 0 ],\n",
    "    [ 1, 1, 0 ],\n",
    "    [ 0, 1, 1 ],\n",
    "    [ 1, 0, 1 ]\n",
    "], dtype=float )\n",
    "\n",
    "Y = samples[ :, 0:1  ]\n",
    "X = samples[ :, 1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 : (0.2540574, array([[0.5481621 ],\n",
      "       [0.54713905],\n",
      "       [0.58101356],\n",
      "       [0.57889146]], dtype=float32))\n",
      "---- 5000 : (0.24938706, array([[0.4816107],\n",
      "       [0.4917439],\n",
      "       [0.5110916],\n",
      "       [0.5179225]], dtype=float32))\n",
      "---- 10000 : (0.24846458, array([[0.47587726],\n",
      "       [0.4968875 ],\n",
      "       [0.5091368 ],\n",
      "       [0.52281   ]], dtype=float32))\n",
      "---- 15000 : (0.24680158, array([[0.4686722 ],\n",
      "       [0.50237095],\n",
      "       [0.50917065],\n",
      "       [0.52820885]], dtype=float32))\n",
      "---- 20000 : (0.24372588, array([[0.4584933 ],\n",
      "       [0.5091864 ],\n",
      "       [0.51195574],\n",
      "       [0.5344176 ]], dtype=float32))\n",
      "---- 25000 : (0.2383976, array([[0.44303027],\n",
      "       [0.51833856],\n",
      "       [0.51839894],\n",
      "       [0.54164314]], dtype=float32))\n",
      "---- 30000 : (0.22987457, array([[0.41914472],\n",
      "       [0.53096765],\n",
      "       [0.52959126],\n",
      "       [0.5500366 ]], dtype=float32))\n",
      "---- 35000 : (0.21723711, array([[0.38451543],\n",
      "       [0.5484345 ],\n",
      "       [0.54665047],\n",
      "       [0.5582644 ]], dtype=float32))\n",
      "---- 40000 : (0.2003144, array([[0.3417371 ],\n",
      "       [0.5708627 ],\n",
      "       [0.5688806 ],\n",
      "       [0.56075895]], dtype=float32))\n",
      "---- 45000 : (0.17980912, array([[0.29964918],\n",
      "       [0.5964438 ],\n",
      "       [0.593103  ],\n",
      "       [0.5486566 ]], dtype=float32))\n",
      "---- 50000 : (0.15591133, array([[0.2657877 ],\n",
      "       [0.62485963],\n",
      "       [0.61838424],\n",
      "       [0.5163733 ]], dtype=float32))\n",
      "---- 55000 : (0.12841094, array([[0.23983651],\n",
      "       [0.65833575],\n",
      "       [0.6488846 ],\n",
      "       [0.4648717 ]], dtype=float32))\n",
      "---- 60000 : (0.09890589, array([[0.21557358],\n",
      "       [0.6983858 ],\n",
      "       [0.6878578 ],\n",
      "       [0.4009335 ]], dtype=float32))\n",
      "---- 65000 : (0.07145004, array([[0.18844935],\n",
      "       [0.74265903],\n",
      "       [0.7319423 ],\n",
      "       [0.33497417]], dtype=float32))\n",
      "---- 70000 : (0.049861416, array([[0.16054495],\n",
      "       [0.78472555],\n",
      "       [0.77423614],\n",
      "       [0.27633056]], dtype=float32))\n",
      "---- 75000 : (0.03495098, array([[0.13596   ],\n",
      "       [0.8196534 ],\n",
      "       [0.8098494 ],\n",
      "       [0.22942677]], dtype=float32))\n",
      "---- 80000 : (0.025235888, array([[0.11628354],\n",
      "       [0.8466461 ],\n",
      "       [0.8377602 ],\n",
      "       [0.1938621 ]], dtype=float32))\n",
      "---- 85000 : (0.018919269, array([[0.10106934],\n",
      "       [0.8671006 ],\n",
      "       [0.85913485],\n",
      "       [0.16720293]], dtype=float32))\n",
      "---- 90000 : (0.014705097, array([[0.08931414],\n",
      "       [0.8827155 ],\n",
      "       [0.8755754 ],\n",
      "       [0.14699064]], dtype=float32))\n",
      "---- 95000 : (0.011793696, array([[0.08010595],\n",
      "       [0.8948558 ],\n",
      "       [0.8884229 ],\n",
      "       [0.13135095]], dtype=float32))\n",
      "---- 100000 : (0.009710705, array([[0.07276126],\n",
      "       [0.9044942 ],\n",
      "       [0.8986616 ],\n",
      "       [0.11898654]], dtype=float32))\n",
      "---- 105000 : (0.008171457, array([[0.0667899 ],\n",
      "       [0.9123048 ],\n",
      "       [0.90697145],\n",
      "       [0.10899625]], dtype=float32))\n",
      "---- 110000 : (0.007001792, array([[0.06185462],\n",
      "       [0.91874826],\n",
      "       [0.91384685],\n",
      "       [0.10078176]], dtype=float32))\n",
      "---- 115000 : (0.0060905972, array([[0.0577094 ],\n",
      "       [0.9241534 ],\n",
      "       [0.9196182 ],\n",
      "       [0.09390458]], dtype=float32))\n",
      "---- 120000 : (0.0053657736, array([[0.05417863],\n",
      "       [0.9287553 ],\n",
      "       [0.92453283],\n",
      "       [0.08807194]], dtype=float32))\n",
      "---- 125000 : (0.0047784094, array([[0.0511337 ],\n",
      "       [0.93271196],\n",
      "       [0.9287656 ],\n",
      "       [0.08304795]], dtype=float32))\n",
      "---- 130000 : (0.0042952294, array([[0.04848617],\n",
      "       [0.9361591 ],\n",
      "       [0.9324542 ],\n",
      "       [0.07868871]], dtype=float32))\n",
      "---- 135000 : (0.0038914017, array([[0.04615728],\n",
      "       [0.9391909 ],\n",
      "       [0.9356981 ],\n",
      "       [0.07485074]], dtype=float32))\n",
      "---- 140000 : (0.0035503553, array([[0.04409003],\n",
      "       [0.9418806 ],\n",
      "       [0.9385795 ],\n",
      "       [0.0714643 ]], dtype=float32))\n",
      "---- 145000 : (0.0032592393, array([[0.04223694],\n",
      "       [0.94427216],\n",
      "       [0.9411373 ],\n",
      "       [0.06842945]], dtype=float32))\n",
      "---- 150000 : (0.0030077875, array([[0.04057598],\n",
      "       [0.946439  ],\n",
      "       [0.9434526 ],\n",
      "       [0.06571418]], dtype=float32))\n",
      "---- 155000 : (0.0027895495, array([[0.03907774],\n",
      "       [0.9483888 ],\n",
      "       [0.94555515],\n",
      "       [0.06327063]], dtype=float32))\n",
      "---- 160000 : (0.0025980142, array([[0.03771788],\n",
      "       [0.95017636],\n",
      "       [0.9474612 ],\n",
      "       [0.06104667]], dtype=float32))\n",
      "---- 165000 : (0.0024289524, array([[0.03647235],\n",
      "       [0.951794  ],\n",
      "       [0.9491927 ],\n",
      "       [0.05899475]], dtype=float32))\n",
      "---- 170000 : (0.0022786628, array([[0.03531742],\n",
      "       [0.9532836 ],\n",
      "       [0.9507837 ],\n",
      "       [0.05711977]], dtype=float32))\n",
      "---- 175000 : (0.0021449663, array([[0.03426376],\n",
      "       [0.95465183],\n",
      "       [0.9522412 ],\n",
      "       [0.05539403]], dtype=float32))\n",
      "---- 180000 : (0.0020245402, array([[0.03328809],\n",
      "       [0.95592606],\n",
      "       [0.95362675],\n",
      "       [0.05382447]], dtype=float32))\n",
      "---- 185000 : (0.0019157336, array([[0.03237639],\n",
      "       [0.95711046],\n",
      "       [0.954872  ],\n",
      "       [0.05233217]], dtype=float32))\n",
      "---- 190000 : (0.0018170247, array([[0.03153431],\n",
      "       [0.9582124 ],\n",
      "       [0.9560653 ],\n",
      "       [0.05096295]], dtype=float32))\n",
      "---- 195000 : (0.001728035, array([[0.03074896],\n",
      "       [0.95922315],\n",
      "       [0.95715076],\n",
      "       [0.04967728]], dtype=float32))\n",
      "[[0.03000499]\n",
      " [0.9602035 ]\n",
      " [0.9581824 ]\n",
      " [0.04848237]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder( tf.float32, shape=( 4, 2 ) )\n",
    "y = tf.placeholder( tf.float32, shape=( 4, 1 ) )\n",
    "\n",
    "l1_weights = tf.Variable( tf.random_uniform( ( 2, 5 ), -1, 1 ) )\n",
    "l1_biases = tf.Variable( tf.zeros( ( 5 ) ) )\n",
    "\n",
    "l1 = tf.sigmoid( tf.matmul( x, l1_weights ) + l1_biases )\n",
    "\n",
    "l2_weights = tf.Variable( tf.random_uniform( ( 5, 1 ), -1, 1 ) )\n",
    "l2_biases = tf.Variable( tf.zeros( ( 1 ) ) )\n",
    "\n",
    "output = tf.sigmoid( tf.matmul( l1, l2_weights ) + l2_biases )\n",
    "\n",
    "# layer = tf.layers.dense( x, units=5, activation=tf.sigmoid, use_bias=True )\n",
    "# output = tf.layers.dense( layer, units=1, activation=tf.sigmoid, use_bias=True )\n",
    "\n",
    "# loss = tf.losses.mean_squared_error( labels=y, predictions=output )\n",
    "cost = tf.reduce_mean(tf.square(Y - output))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer( 0.01 ).minimize( cost )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run( init )\n",
    "\n",
    "for train_sessions in range( 200000 ):\n",
    "    feed_dict = { x: X, y: Y }\n",
    "    _ = sess.run( train_step, feed_dict=feed_dict )\n",
    "    if ( train_sessions ) % 5000 == 0:\n",
    "        print( '----', train_sessions, ':', sess.run( ( cost, output ), feed_dict=feed_dict ) )\n",
    "\n",
    "final_outputs = sess.run( output, feed_dict={ x: X, y: Y } )\n",
    "print( final_outputs )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
