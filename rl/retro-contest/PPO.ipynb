{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, backend as K, losses, models, optimizers\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retro_contest.local import make\n",
    "env = make(\n",
    "    game='SonicTheHedgehog-Genesis', \n",
    "    state='GreenHillZone.Act1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_actions = [\n",
    "#     B  A  M  S  U  D  L  R  C  Y  X  Z\n",
    "    [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ], # {}\n",
    "    [ 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0 ], # { LEFT }\n",
    "    [ 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0 ], # { RIGHT }, \n",
    "    [ 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0 ], # { LEFT, DOWN }, \n",
    "    [ 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0 ], # { RIGHT, DOWN }, \n",
    "    [ 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0 ], # { DOWN }, \n",
    "    [ 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0 ], # { DOWN, B }, \n",
    "    [ 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]  # { B }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "\n",
    "\n",
    "class RetroProcessor( Processor ):\n",
    "    def process_observation( self, obs ):\n",
    "        img = Image.fromarray( obs )\n",
    "        img = img.resize( INPUT_SHAPE ).convert( 'L' )\n",
    "\n",
    "        return np.array( img, dtype=np.uint8 )\n",
    "\n",
    "    def process_state_batch( self, batch ):\n",
    "        return batch.astype( np.float32 ) / 255.\n",
    "\n",
    "    def process_reward( self, reward ):\n",
    "        return np.clip( reward, -1., 1. ) # Why clip?\n",
    "\n",
    "    def process_action( self, action ):\n",
    "        return actual_actions[ action ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO Loosely based on baselines/ppo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input_layer = layers.Input( ( 1, 84, 84 ) )\n",
    "\n",
    "x = layers.Permute( ( 2, 3, 1 ) )( x )\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=( 8, 8 ),\n",
    "    strides=4,\n",
    "    activation='relu'\n",
    ")( x )\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=( 4, 4 ),\n",
    "    strides=2,\n",
    "    activation='relu'\n",
    ")( x )\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=( 3, 3 ),\n",
    "    strides=1,\n",
    "    activation='relu'\n",
    ")( x )\n",
    "\n",
    "x = layers.Flatten()( x )\n",
    "\n",
    "x = layers.Dense( 512, activation='relu' )( x )\n",
    "x = layers.Dense( len( actual_actions ), activation='linear' )( x )\n",
    "\n",
    "model = models.Model( inputs=input_layer, outputs=x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = LinearAnnealedPolicy(\n",
    "    EpsGreedyQPolicy(), \n",
    "    attr='eps', \n",
    "    value_max=1., \n",
    "    value_min=.1, \n",
    "    value_test=.05,\n",
    "    nb_steps=1000000\n",
    ")\n",
    "\n",
    "memory = SequentialMemory( limit=100000, window_length=1 )\n",
    "processor = RetroProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(\n",
    "    model=model, \n",
    "    nb_actions=len( actual_actions ), \n",
    "    policy=policy, \n",
    "    memory=memory,\n",
    "    processor=processor, \n",
    "    nb_steps_warmup=50000, \n",
    "    gamma=.99, \n",
    "    target_model_update=10000,\n",
    "    train_interval=1,\n",
    "    delta_clip=1.\n",
    ")\n",
    "dqn.compile( optimizers.Adam( lr=.00025 ), metrics=[ 'mae' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    }
   ],
   "source": [
    "# Okay, now it's time to learn something! We capture the interrupt exception so that training\n",
    "# can be prematurely aborted. Notice that you can the built-in Keras callbacks!\n",
    "# weights_filename = 'dqn_weights.h5f'\n",
    "\n",
    "# checkpoint_weights_filename = 'dqn_' + args.env_name + '_weights_{step}.h5f'\n",
    "# log_filename = 'dqn_{}_log.json'.format(args.env_name)\n",
    "# callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
    "# callbacks += [FileLogger(log_filename, interval=100)]\n",
    "dqn.fit(\n",
    "    env, \n",
    "#     callbacks=callbacks, \n",
    "    nb_steps=10, \n",
    "    log_interval=1\n",
    ")\n",
    "\n",
    "# After training is done, we save the final weights one more time.\n",
    "dqn.save_weights( 'data/wrights', overwrite=True )\n",
    "\n",
    "# Finally, evaluate our algorithm for 10 episodes.\n",
    "dqn.test( env, nb_episodes=10, visualize=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
